# -*- coding: utf-8 -*-
"""vgg16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y7WpCQ4tIEb4ecCgjsMg0Ij_6ZyVltFq
"""

from google.colab import drive
drive.mount("/content/drive/", force_remount=True)

import json
import math
import os
from glob import glob 
from tqdm import tqdm
from PIL import Image
import cv2 
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt 


from sklearn.metrics import accuracy_score 
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report 
from sklearn.model_selection import train_test_split

from keras import layers
from keras.models import Sequential
from keras.optimizers import Adam, RMSprop
from keras.applications import VGG16
from keras.utils.np_utils import to_categorical
from keras.layers import  Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense,BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam,RMSprop,SGD

!pip install tensorflow

import tensorflow

train_datagen = ImageDataGenerator(rescale = 1.0 / 255.0,
                                   zoom_range = 0.4,
                                   rotation_range = 10,
                                   horizontal_flip = True,
                                   vertical_flip = True,
                                   validation_split = 0.2)

valid_datagen = ImageDataGenerator(rescale = 1.0 / 255.0,
                                   validation_split = 0.2)

test_datagen  = ImageDataGenerator(rescale = 1.0 / 255.0)

train_dataset  = train_datagen.flow_from_directory(directory = '/content/drive/MyDrive/train1',
                                                   target_size = (224,224),
                                                   class_mode = 'binary',
                                                   batch_size =16, 
                                                   )

valid_dataset = valid_datagen.flow_from_directory(directory = '/content/drive/MyDrive/validation1',
                                                  target_size = (224,224),
                                                  class_mode = 'binary',
                                                  batch_size = 16, 
                                                 )

train_dataset.class_indices

images = ['/content/drive/MyDrive/train1/covid/COVID (1).png',
'/content/drive/MyDrive/train1/normal/NORMAL (1).png',
'/content/drive/MyDrive/validation1/pneumonia/Viral Pneumonia (1).png',
'/content/drive/MyDrive/train1/covid/COVID (10).png',
'/content/drive/MyDrive/train1/normal/NORMAL (10).png',
'/content/drive/MyDrive/validation1/pneumonia/Viral Pneumonia (10).png',
'/content/drive/MyDrive/train1/covid/COVID (100).png',
'/content/drive/MyDrive/train1/normal/NORMAL (100).png',
'/content/drive/MyDrive/validation1/pneumonia/Viral Pneumonia (100).png']

fig, axes = plt.subplots(3, 3, figsize=(7, 7))
labels = ['Covid', 'Normal', 'Pneumonia']
i = 0
j = 0

for row in axes:
    for plot in row:
        plot.imshow(cv2.imread(images[j], 0))
        plot.axhline(y=0.5, color='r')
        plot.set_title(labels[i], fontsize=15)
        plot.axis('off')
        i += 1
        j += 1
    i = 0
    
fig.tight_layout()
plt.show()

base_model = VGG16(input_shape=(224,224,3), 
                   include_top=False,
                   weights="imagenet")

for layer in base_model.layers:
    layer.trainable=False

base_model.summary()

model=Sequential()
model.add(base_model)
model.add(Dropout(0.2))
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(1024,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(1024,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(1,activation='sigmoid'))

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

model.summary()

OPT    = tensorflow.keras.optimizers.Adam(lr=2e-5)

model.compile(loss='binary_crossentropy',
              metrics=[tensorflow.keras.metrics.AUC(name = 'acc')],
              optimizer=OPT)

filepath = './best_weights.hdf5'

earlystopping = EarlyStopping(monitor = 'val_acc', 
                              mode = 'max' , 
                              patience = 10,
                              verbose = 1)

checkpoint    = ModelCheckpoint(filepath, 
                                monitor = 'val_acc', 
                                mode='max', 
                                 
                                verbose = 1)


callback_list = [earlystopping, checkpoint]

model_history=model.fit(train_dataset,
                        validation_data=valid_dataset,
                        epochs = 10,
                       
                        verbose=1,
                        callbacks = callback_list,
                        )

plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))
plt.show()

plt.plot(model_history.history['acc'])
plt.plot(model_history.history['val_acc'])
plt.title('Model ACC')
plt.ylabel('ACC')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))
plt.show()